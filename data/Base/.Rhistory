geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =1.5)+
labs(x= "Puntos", y = "Ancho del sépalo (en cm)", title = "Comparacion del histograma de frecuencias de la distribucion binomial negativa simulada y una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =1.5)+
labs(x= "Puntos", y = "Ancho del sépalo (en cm)", title = "Histograma de frecuencias de la distribucion binomial negativa simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =1.5)+
labs(x= "Puntos", y = "Ancho del sépalo (en cm)", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =0.8)+
labs(x= "Puntos", y = "Ancho del sépalo (en cm)", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con funcion de r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados entre ambas simulaciones
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, color = "green",fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =0.8)+
labs(x= "Puntos", y = "Ancho del sépalo (en cm)", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con funcion de r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados entre ambas simulaciones
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, color = "green",fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =0.8)+
labs(x= "", y = "Ancho del sépalo (en cm)", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con funcion de r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados entre ambas simulaciones
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, color = "green",fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =0.8)+
labs(x= "", y = "Frecuencia", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
# Simulacion de puntos de distribucion binomial negativa con funcion de r
x <- 1:100
simulation_r <- dnbinom(x,size=nbrExitos,prob=nbrProbExito)
# Graficos para comparar resultados entre ambas simulaciones
ggplot() +
geom_histogram(aes(x = simBinNeg, y = ..density..), binwidth = 1, color = "green",fill ="blue", alpha =0.3) +
geom_point(aes(x = x+10, y = simulation_r), colour = 'red', size =0.8)+
labs(x= "", y = "Frecuencia relativa", title = "Histograma de frecuencias de la distribucion binomial negativa \n simulada vs distribución una obtenida con dnbinom")
kalman = function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T)
Sigma.p = array(0, c(dx, dx, T))
mu.f = matrix(0, nrow = dx, ncol = T)
Sigma.f = array(0, c(dx, dx, T))
mu.s = matrix(0, nrow = dx, ncol = T)
Sigma.s = array(0, c(dx, dx, T))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T] = mu.f[, T]
Sigma.s[, , T] = Sigma.f[, , T]
for (t in (T - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
kalman = function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T)
Sigma.p = array(0, c(dx, dx, T))
mu.f = matrix(0, nrow = dx, ncol = T)
Sigma.f = array(0, c(dx, dx, T))
mu.s = matrix(0, nrow = dx, ncol = T)
Sigma.s = array(0, c(dx, dx, T))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T] = mu.f[, T]
Sigma.s[, , T] = Sigma.f[, , T]
for (t in (T - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
View(kalman)
T
function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T0 = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T0)
Sigma.p = array(0, c(dx, dx, T0))
mu.f = matrix(0, nrow = dx, ncol = T0)
Sigma.f = array(0, c(dx, dx, T0))
mu.s = matrix(0, nrow = dx, ncol = T0)
Sigma.s = array(0, c(dx, dx, T0))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T0)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T0 = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T0)
Sigma.p = array(0, c(dx, dx, T0))
mu.f = matrix(0, nrow = dx, ncol = T0)
Sigma.f = array(0, c(dx, dx, T0))
mu.s = matrix(0, nrow = dx, ncol = T0)
Sigma.s = array(0, c(dx, dx, T0))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T0)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T0)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
ggplot2()+ geom_point(aes(1:50,mu.f))
library(tidyverse)
ggplot2()+ geom_point(aes(1:50,mu.f))
ggplot()+ geom_point(aes(1:50,mu.f))
ggplot()+ geom_point(aes(1:50,mu.f[2,]))
mu.f
dim(mu.f)
ggplot()+ geom_point(aes(1:50,mu.f[1,]))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,x, color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'red'))
ggplot()+ geom_point(aes(1:50,mu.f[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
mu.p = results.KF$mu.p
mu.s = results.KF$mu.s
ggplot()+ geom_point(aes(1:50,mu.s[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
library(tidyverse)
function(y, F, G, Q, H, R, mu0, Sigma0){
dy = nrow(y)
T0 = ncol(y)
dx = length(mu0)
I = diag(dx)
## INITIALIZATION ##
mu.p = matrix(0, nrow = dx, ncol = T0)
Sigma.p = array(0, c(dx, dx, T0))
mu.f = matrix(0, nrow = dx, ncol = T0)
Sigma.f = array(0, c(dx, dx, T0))
mu.s = matrix(0, nrow = dx, ncol = T0)
Sigma.s = array(0, c(dx, dx, T0))
## FORWARD RECURSION ## Time 1
mu.p[, 1] = F %*% mu0
Sigma.p[, , 1] = F %*% Sigma0 %*% t(F) + G %*% Q %*% t(G)
nu = y[, 1] - H %*% mu.p[, 1]
S = H %*% Sigma.p[, , 1] %*% t(H) + R
K = Sigma.p[, , 1] %*% t(H) %*% solve(S)
mu.f[, 1] = mu.p[, 1] + K %*% nu
Sigma.f[, , 1] = (I - K %*% H) %*% Sigma.p[, , 1]
# Time 2:T
for (t in (2:T0)){
# Prediction
mu.p[, t] = F %*% mu.f[, t - 1]
Sigma.p[, , t] = F %*% Sigma.f[, , t - 1] %*% t(F) + G %*% Q %*% t(G)
# Update
nu = y[, t] - H %*% mu.p[, t]
S = H %*% Sigma.p[, , t] %*% t(H) + R
K = Sigma.p[, , t] %*% t(H) %*% solve(S)
mu.f[, t] = mu.p[, t] + K %*% nu
Sigma.f[, , t] = (I - K %*% H) %*% Sigma.p[, , t]}
## BACKWARD RECURSION ##
mu.s[, T0] = mu.f[, T0]
Sigma.s[, , T0] = Sigma.f[, , T0]
for (t in (T0 - 1):1){
J = Sigma.f[, , t] %*% t(F) %*% solve(Sigma.p[, , t + 1])
mu.s[, t] = mu.f[, t] + J %*% (mu.s[, t + 1] - mu.p[, t + 1])
Sigma.s[, , t] = Sigma.f[, , t] + J %*% (Sigma.s[, , t + 1] - Sigma.p[,, t + 1]) %*% t(J)
}
return(list(mu.f = mu.f, Sigma.f = Sigma.f, mu.p = mu.p, Sigma.p = Sigma.p,mu.s = mu.s, Sigma.s = Sigma.s))
}
T0 = 50
x = matrix(cos(c(1:T0)/10), 1, T0)
R = 0.2
mu0 = 0
Sigma0 = 1
G = 1
Q = 0.02
H = 1
F0 = 1
y = matrix(x + rnorm(T0, sd = sqrt(R)), nrow = 1, ncol = T0)
results.KF = kalman(y, F0, G, Q, H, R, mu0, Sigma0)
mu.f = results.KF$mu.f
Sigma.f = results.KF$Sigma.f
mu.p = results.KF$mu.p
mu.s = results.KF$mu.s
ggplot()+ geom_point(aes(1:50,mu.p[1,], color = 'red'))+geom_point(aes(1:50,y[1,], color = 'blue'))
?gamma
?dgamma
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
alpha1 <- 16/136.5
beta1 <- alpha1/136.5
s1 <- 1/beta1
# probabilidad de que theta sea menor a 0.1
pgamma(0.1, alpha1, s1)
qgamma(0.1, alpha1, s1)
pgamma(0.01, alpha1, s1)
?pnorm
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- alpha1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- alpha1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
sigma1 <- alpha1/136.5
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.01, mu1, sigma1)
# Ejercicio 6 b)
# Simulacion para caso 1
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.1, mu1, sigma1)
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
pnorm(0.1, mu2, sigma2)
# probabilidad de que theta sea menor a 0.1
print("Caso 1")
pnorm(0.1, mu1, sigma1)
###### ----- Simulacion para caso 2 ----- ######
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
print("Caso 2")
pnorm(0.1, mu2, sigma2)
print("Caso 1")
pnorm(0.1, mu1, sigma1)
mu1 <- 16/136.5
sigma1 <- mu1/136.5
# probabilidad de que theta sea menor a 0.1
print("Caso 1")
pnorm(0.1, mu1, sigma1)
mu2 <- 9/92.5
sigma2 <- mu2/92.5
# probabilidad de que theta sea menor a 0.1
print("Caso 2")
pnorm(0.1, mu2, sigma2)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library("tidyverse")
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(gridExtra)
library(grid)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(gridExtra)
library(grid)
N = 14; z = 11; a = 1; b = 1
base <- ggplot(data_frame(x = c(0, 1)), aes(x))
p1 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b), #inicial
aes(colour = "inicial"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1), #verosimilitud
aes(colour = "verosimilitud"), show.legend = FALSE) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b), #posterior
aes(colour = "posterior"), show.legend = FALSE) +
labs(y = "", colour = "", x = expression(theta))
N = 14; z = 11; a = 100; b = 100
p2 <- base +
stat_function(fun = dbeta, args = list(shape1 = a, shape2 = b),
aes(colour = "inicial")) +
stat_function(fun = dbeta, args = list(shape1 = z + 1, shape2 = N - z + 1),
aes(colour = "verosimilitud")) +
stat_function(fun = dbeta, args = list(shape1 = a + z, shape2 = N - z + b),
aes(colour = "posterior")) +
labs(y = "", colour = "", x = expression(theta))
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
View(p1)
p1
p2
grid.arrange(p1, p2, nrow = 1, widths = c(0.38, 0.62))
library(shiny); runApp('/media/Box/Aprendizaje_Maquina/Projecto/BAF_shiny.R')
beta(1,1)
beta(0.4,0.9)
choose(66,64)
devtools::install_github('diegovalle/mxmaps')
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
install.packages(c("bayesm", "bayestestR", "callr", "covr", "data.table", "digest", "DT", "funModeling", "future", "ggvis", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmltools", "htmlwidgets", "insight", "jomo", "kernlab", "knitr", "later", "pkgbuild", "plotly", "promises", "purrr", "qvcalc", "R6", "RcppArmadillo", "rlang", "rmarkdown", "roxygen2", "rvest", "shiny", "sp", "testthat", "tinytex", "xfun"))
devtools::install_github('diegovalle/mxmaps')
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
devtools::install_github('diegovalle/mxmaps')
install.packages("tidyverse")
devtools::install_github('diegovalle/mxmaps')
install.packages("devtools")
devtools::install_github('diegovalle/mxmaps')
library(mxmaps)
install.packages(c("R2OpenBUGS", "R2jags"))
install.packages("corrplot")
library(shiny); runApp('/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/shiny_dashboard.R')
runApp('/media/Box/Modelos_Lineales_Generalizados/Projecto/data/Base/shiny_dashboard.R')
